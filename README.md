# ü§ñ Clasificador de Anuncios con IA

Este proyecto es una aplicaci√≥n web interactiva que utiliza modelos de lenguaje grandes (LLMs) para clasificar textos e im√°genes, determinando si son anuncios o no. Permite configurar diferentes modelos (Google Gemini, OpenAI GPT, o modelos locales a trav√©s de LM Studio) y gestionar ejemplos para mejorar la precisi√≥n del clasificador.

## ‚ú® Caracter√≠sticas

*   **Clasificaci√≥n de Texto:** Introduce cualquier texto y el modelo lo clasificar√° como "anuncio" o "no_anuncio", proporcionando una breve explicaci√≥n.
*   **Procesamiento de Im√°genes:** Sube una imagen y un modelo de visi√≥n generar√° una descripci√≥n detallada, que luego podr√°s usar para clasificarla como anuncio o no.
*   **Configuraci√≥n de Modelos:** Cambia f√°cilmente entre diferentes proveedores de LLMs (Google API, OpenAI API, LM Studio) y configura sus credenciales o detalles de conexi√≥n directamente desde la interfaz web.
*   **Gesti√≥n de Ejemplos:** A√±ade, edita y elimina ejemplos de clasificaci√≥n para entrenar y mejorar el rendimiento del modelo.
*   **Interfaz Intuitiva:** Dise√±o limpio y moderno basado en Bootstrap para una experiencia de usuario agradable.

## üöÄ Tecnolog√≠as Utilizadas

*   **Backend:** Python 3.x con Flask
*   **LLM Framework:** DSPy
*   **APIs de LLM:**
    *   Google Generative AI (para modelos Gemini)
    *   OpenAI (para modelos GPT)
    *   LM Studio (para modelos locales que emulan la API de OpenAI)
*   **Frontend:** HTML, CSS (Bootstrap 5), JavaScript
*   **Manejo de Im√°genes:** Pillow (PIL)

## üìã Prerrequisitos

Antes de empezar, aseg√∫rate de tener instalado lo siguiente:

*   **Python 3.11+**
*   **pip** (gestor de paquetes de Python)
*   **Homebrew** (recomendado para macOS para instalar `gcloud CLI`)
*   **Google Cloud CLI (`gcloud`)** (Opcional): Solo necesario si planeas usar la autenticaci√≥n de Google Cloud (Application Default Credentials) en lugar de una API Key directa para la Google API. Si solo usas una API Key, puedes omitir este paso.
    *   Inst√°lalo con Homebrew: `brew install --cask google-cloud-sdk`
    *   O sigue las instrucciones oficiales: [Instalar gcloud CLI](https://cloud.google.com/sdk/docs/install)
*   **LM Studio** (Opcional, si deseas usar modelos locales): Desc√°rgalo desde [LM Studio](https://lmstudio.ai/). Aseg√∫rate de cargar un modelo de visi√≥n compatible (ej. LLaVA, Gemma-3-4b) y de que su servidor est√© corriendo en la IP y puerto configurados.

## ‚öôÔ∏è Instalaci√≥n y Configuraci√≥n

Sigue estos pasos para poner el proyecto en marcha:

1.  **Clona el repositorio:**
    ```bash
    git clone <URL_DEL_REPOSITORIO>
    cd clasificador_anuncios
    ```

2.  **Crea y activa un entorno virtual:**
    ```bash
    python3 -m venv venv
    source venv/bin/activate
    ```

3.  **Instala las dependencias de Python:**
    ```bash
    pip install -r requirements.txt
    pip install Pillow google-generativeai openai # Aseg√∫rate de que estas est√©n instaladas
    ```
    *(Nota: `requirements.txt` deber√≠a contener la mayor√≠a, pero estas √∫ltimas son cruciales para la funcionalidad de imagen y pueden no estar siempre en el `requirements.txt` inicial.)*

4.  **Configura tus API Keys (si usas Google o OpenAI):**
    *   La aplicaci√≥n gestiona las API Keys a trav√©s de la interfaz web en la secci√≥n "Configuraci√≥n del Modelo".
    *   **Para Google API:** Necesitar√°s una API Key de Google Generative AI. Puedes obtenerla en [Google AI Studio](https://aistudio.google.com/app/apikey).
    *   **Para OpenAI API:** Necesitar√°s una API Key de OpenAI. Puedes obtenerla en [OpenAI API Keys](https://platform.openai.com/api-keys).
    *   **Importante:** Nunca subas tus API Keys directamente al c√≥digo fuente en GitHub. Este proyecto las gestiona a trav√©s de un archivo `config.json` que se crea localmente.

5.  **Configura LM Studio (si usas modelos locales):**
    *   Abre LM Studio y descarga un modelo de visi√≥n (ej. `google/gemma-3-4b` o un modelo LLaVA).
    *   Inicia el servidor del modelo en LM Studio. Anota la IP y el puerto (por defecto suele ser `http://localhost:1234`).
    *   En la interfaz web de la aplicaci√≥n, selecciona "LM Studio (Local)" y configura la IP y el Puerto.

## ‚ñ∂Ô∏è Ejecutar la Aplicaci√≥n

Para iniciar el servidor Flask, aseg√∫rate de estar en el directorio `clasificador_anuncios/` y ejecuta:

```bash
source venv/bin/activate # Si no est√° activado
python app.py
```

El servidor se iniciar√° en `http://127.0.0.1:5000`. Abre esta URL en tu navegador web.

## üí° Uso

Una vez que la aplicaci√≥n est√© corriendo:

*   **Clasificar Texto:** Escribe un texto en el campo principal y haz clic en "Clasificar".
*   **Procesar Imagen:** Sube una imagen en la secci√≥n "Procesar Imagen". Haz clic en "Procesar Imagen" para que el modelo genere una descripci√≥n. Esta descripci√≥n se cargar√° en el campo de texto principal, lista para ser clasificada.
*   **Configuraci√≥n del Modelo:** En la columna de la derecha, selecciona el tipo de modelo que deseas usar (LM Studio, OpenAI, Google) y proporciona las credenciales o detalles de conexi√≥n necesarios. Haz clic en "Guardar Configuraci√≥n".
*   **Gesti√≥n de Ejemplos:** En la secci√≥n inferior, puedes a√±adir nuevos ejemplos para mejorar el modelo. Haz clic en "Ver Ejemplos Existentes" para expandir la lista y usar los botones de "Acciones" para editar o eliminar ejemplos.

## ‚ö†Ô∏è Soluci√≥n de Problemas Comunes

*   **`Address already in use`**: Si el puerto 5000 ya est√° en uso, significa que una instancia anterior del servidor no se cerr√≥ correctamente.
    1.  En tu terminal, busca el proceso que usa el puerto: `lsof -i :5000`
    2.  Termina el proceso usando su PID (reemplaza `PID_DEL_PROCESO`): `kill -9 PID_DEL_PROCESO`
    3.  Vuelve a iniciar la aplicaci√≥n.
*   **`API Key no configurada`**: Aseg√∫rate de haber introducido tu API Key en la interfaz web y haber guardado la configuraci√≥n.
*   **`Model "..." not found` (LM Studio)**: Verifica que el nombre del modelo en la configuraci√≥n de la aplicaci√≥n (`config.json` o la interfaz web) coincida exactamente con el nombre del modelo que tienes cargado y ejecut√°ndose en LM Studio.
*   **`Error processing image: ...`**:
    *   Aseg√∫rate de que el modelo seleccionado (Google, OpenAI, LM Studio) sea un modelo de visi√≥n.
    *   Verifica que tu API Key sea correcta y tenga los permisos necesarios.
    *   Para LM Studio, confirma que el servidor del modelo est√© activo y accesible en la IP/Puerto configurados.

## ü§ù Contribuciones

¬°Las contribuciones son bienvenidas! Si deseas mejorar este proyecto, por favor, abre un "issue" o env√≠a un "pull request".

## üìÑ Licencia

Este proyecto est√° bajo la licencia MIT. Consulta el archivo `LICENSE` para m√°s detalles.
